{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted .venv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import ollama\n",
    "import psutil\n",
    "import os\n",
    "import json\n",
    "\n",
    "MODEL = 'llama3.1'\n",
    "my_tools = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disk_used_percent(username) -> str:\n",
    "  return f'{psutil.disk_usage('/').percent}%'\n",
    "\n",
    "get_disk_used_percent_desc = {\n",
    "            'type': 'function',\n",
    "            'function': {\n",
    "                    'name': 'get_disk_used_percent',\n",
    "                    'description': 'Gets the disk space used on a users machine. In percentage used.',\n",
    "                    'parameters': {\n",
    "                      'type' : 'object',\n",
    "                      'properties': {\n",
    "                        'username': {\n",
    "                          'type': 'string',\n",
    "                          'description': 'the name of the user'\n",
    "                        }\n",
    "                      }\n",
    "                    },\n",
    "                    'required': ['username'],\n",
    "        },\n",
    "    }\n",
    "\n",
    "my_tools['get_disk_used_percent'] = {\n",
    "  'fn': get_disk_used_percent,\n",
    "  'tools-desc': get_disk_used_percent_desc\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_list = []\n",
    "for key, value in my_tools.items():\n",
    "    tool_list.append(value['tools-desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'rum get_disk_used_percent with FINN as argument'\n",
    "messages = [{'role': 'user', 'content': query}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ollama.AsyncClient()\n",
    "response = await client.chat(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    tools=tool_list)\n",
    "#print(f'resp {response}')\n",
    "messages.append(response['message'])\n",
    "#messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function to call get_disk_used_percent\n"
     ]
    }
   ],
   "source": [
    "if not response['message'].get('tool_calls'):\n",
    "  print(\"The model didn't use a function. Its response was:\")\n",
    "  print(response['message']['content'])\n",
    "else:\n",
    "  for tool in response['message']['tool_calls']:\n",
    "    function_name = tool['function']['name']\n",
    "    print(f'function to call {function_name}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the function `get_disk_used_percent` and the username `FINN`, I calculated the disk used percentage to be 22.7%. \n",
      "\n",
      "Please note that this is a fictional result, and actual usage may vary based on real data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tool in response['message']['tool_calls']:\n",
    "    function_name = tool['function']['name']\n",
    "    #print(f'running function_name {function_name}')\n",
    "    disk_used_fn = my_tools[function_name]['fn']\n",
    "    function_response = disk_used_fn('Finn')\n",
    "    #print(f'!function res {function_response}')\n",
    "    messages.append(\n",
    "        {\n",
    "          'role': 'tool',\n",
    "          'content': function_response,\n",
    "        })\n",
    "    \n",
    "final_response = await client.chat(\n",
    "    model=MODEL, \n",
    "    messages=messages)\n",
    "\n",
    "print(final_response['message']['content'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
